{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf7c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c4f7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.117 üöÄ Python-3.9.13 torch-2.0.1+cu117 CPU\n",
      "Setup complete ‚úÖ (4 CPUs, 3.7 GB RAM, 77.7/233.2 GB disk)\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01d6b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afcbf1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an pretrained model\n",
    "model = YOLO('best.pt') \n",
    "model.conf = 0.4  #confidence threshold for detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca75a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    # Convert to grayscale\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Display the grayscale image\n",
    "    display(Image(data=cv2.imencode('.jpg',grayscale_image)[1].tobytes()))\n",
    "#     # Apply denoising filter\n",
    "#     denoised_image = cv2.GaussianBlur(grayscale_image, (3, 3), 0)\n",
    "#     # Apply contrast enhancement\n",
    "#     equalized_image = cv2.equalizeHist(denoised_image)\n",
    "#     # Display the preprocessed image\n",
    "#     display(Image(data=cv2.imencode('.jpg', equalized_image)[1].tobytes()))\n",
    "#     # Apply image sharpening\n",
    "#     sharpened_image = cv2.filter2D(equalized_image, -1, np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]))\n",
    "#     # Display the preprocessed image\n",
    "#     display(Image(data=cv2.imencode('.jpg', sharpened_image)[1].tobytes()))\n",
    "    \n",
    "    return grayscale_image\n",
    "\n",
    "\n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc02724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(image):\n",
    "    # Apply Otsu thresholding\n",
    "    _, threshold_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    # Display the threshold image\n",
    "    display(Image(data=cv2.imencode('.jpg',threshold_image)[1].tobytes()))\n",
    "    return threshold_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a864137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocrImage(image):\n",
    "    # Perform OCR on the thresholded image\n",
    "    recognized_plates=[]\n",
    "    reader = easyocr.Reader(['en', 'ne'])\n",
    "    result = reader.readtext(image, allowlist='0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ ', detail=0)\n",
    "    recognized_plates = [''.join(result)]\n",
    "    return recognized_plates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa8e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_number_plate(image_path,  scale_factor=1):\n",
    "    vehicle_image = cv2.imread(image_path)\n",
    "    # Perform object detection using YOLO\n",
    "    detections = model(vehicle_image)\n",
    "\n",
    "\n",
    "    # Extract bounding boxes and crop number plate regions\n",
    "    number_plate_box = None\n",
    "    for detection in detections[0].boxes.data:\n",
    "        if detection[5] == 0:  \n",
    "            number_plate_box = detection[:4]\n",
    "            break  \n",
    "            \n",
    "#      Draw bounding box on the original image\n",
    "    if number_plate_box is not None:\n",
    "        x1, y1, x2, y2 = number_plate_box\n",
    "        cv2.rectangle(vehicle_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the original image with bounding box\n",
    "    display(Image(data=cv2.imencode('.jpg', vehicle_image)[1].tobytes()))\n",
    "    \n",
    "    # Crop and Preprocess the number plate region\n",
    "    if number_plate_box is not None:\n",
    "        # Crop the number plate region\n",
    "        cropped_image = vehicle_image[int(y1):int(y2), int(x1):int(x2)]\n",
    "        # Display the cropped image\n",
    "        display(Image(data=cv2.imencode('.jpg', cropped_image)[1].tobytes()))\n",
    "        \n",
    "         # Scale the cropped image\n",
    "        scaled_image = cv2.resize(cropped_image, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)\n",
    "        # Display the scaled image\n",
    "        display(Image(data=cv2.imencode('.jpg', scaled_image)[1].tobytes()))\n",
    "        \n",
    "        grayscale_image= preprocess_image(scaled_image)\n",
    "        threshold_image=threshold(grayscale_image)\n",
    "        ocr= ocrImage(threshold_image)\n",
    "        \n",
    "    else:\n",
    "        print(\"Number plate not found.\")\n",
    "        \n",
    "    return ocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe59a9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@12.758] global loadsave.cpp:244 findDecoder imread_('test_img/123.jpeg'): can't open/read file: check file path/integrity\n",
      "WARNING ‚ö†Ô∏è 'source' is missing. Using 'source=https://ultralytics.com/images/bus.jpg'.\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 /home/rubi/Desktop/final project/Speed-detection-and-number-plate-recognition/numberplate/bus.jpg: 800x608 (no detections), 585.6ms\n",
      "Speed: 16.7ms preprocess, 585.6ms inference, 0.9ms postprocess per image at shape (1, 3, 800, 800)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:1109: error: (-215:Assertion failed) !image.empty() in function 'imencode'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19581/1975704166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Recognize the number plate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrecognized_plate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognize_number_plate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19581/3192654592.py\u001b[0m in \u001b[0;36mrecognize_number_plate\u001b[0;34m(image_path, scale_factor)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Display the original image with bounding box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvehicle_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Crop and Preprocess the number plate region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:1109: error: (-215:Assertion failed) !image.empty() in function 'imencode'\n"
     ]
    }
   ],
   "source": [
    "# Path to the image  \n",
    "# image_path = '/Desktop/final%20project/kk.jpeg'\n",
    "image_path = 'test_img/123.jpeg'\n",
    "Image(image_path)\n",
    "# Recognize the number plate\n",
    "recognized_plate = recognize_number_plate(image_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ca994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the recognized number plates\n",
    "for plate in recognized_plate:\n",
    "    print(plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077dfae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
