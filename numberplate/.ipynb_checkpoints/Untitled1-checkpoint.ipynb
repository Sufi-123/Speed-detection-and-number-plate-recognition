{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba99639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.117 ðŸš€ Python-3.9.13 torch-2.0.1+cu117 CPU\n",
      "Setup complete âœ… (4 CPUs, 3.7 GB RAM, 90.6/233.2 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "from IPython.display import display, Image\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "from ultralytics import YOLO\n",
    "import functools\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035a9e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    # Convert to grayscale\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Display the grayscale image\n",
    "    display(Image(data=cv2.imencode('.jpg',grayscale_image)[1].tobytes()))\n",
    "    #gaussian blur\n",
    "    blur= cv2.GaussianBlur(grayscale_image,(5,5),0)\n",
    "     # Display the grayscale image\n",
    "    display(Image(data=cv2.imencode('.jpg',blur)[1].tobytes()))\n",
    "    \n",
    "    return blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538f03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(image):\n",
    "    # Apply Otsu thresholding\n",
    "    _, threshold_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Invert the colors\n",
    "    inverted_image = cv2.bitwise_not(threshold_image)\n",
    "    \n",
    "    # Display the threshold image\n",
    "    display(Image(data=cv2.imencode('.jpg',inverted_image)[1].tobytes()))\n",
    "    return inverted_image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dcc6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_characters(image):\n",
    "    # Perform connected components analysis on the thresholded image and\n",
    "    # initialize the mask to hold only the components we are interested in\n",
    "    _, labels = cv2.connectedComponents(image)\n",
    "    mask = np.zeros(image.shape, dtype=\"uint8\")\n",
    "    \n",
    "    # Set lower bound and upper bound criteria for characters\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    lower = total_pixels // 100  # heuristic param, can be fine-tuned if necessary\n",
    "    upper = total_pixels // 10  # heuristic param, can be fine-tuned if necessary\n",
    "\n",
    "    # Loop over the unique components\n",
    "    bounding_boxes = []\n",
    "    for (i, label) in enumerate(np.unique(labels)):\n",
    "        # If this is the background label, ignore it\n",
    "        if label == 255:\n",
    "            continue\n",
    "\n",
    "        # Otherwise, construct the label mask to display only connected component\n",
    "        # for the current label\n",
    "        labelMask = np.zeros(image.shape, dtype=\"uint8\")\n",
    "        labelMask[labels == label] = 255\n",
    "        numPixels = cv2.countNonZero(labelMask)\n",
    "\n",
    "        # If the number of pixels in the component is between lower bound and upper bound, \n",
    "        # add it to our mask and compute the bounding box\n",
    "        if numPixels > lower and numPixels < upper:\n",
    "            mask = cv2.add(mask, labelMask)\n",
    "            \n",
    "            # Compute the bounding box of the component\n",
    "            (x, y, w, h) = cv2.boundingRect(labelMask)\n",
    "            bounding_boxes.append((x, y, w, h))\n",
    "\n",
    "    # Sort the bounding boxes from left to right, top to bottom\n",
    "    def compare(rect1, rect2):\n",
    "        if abs(rect1[1] - rect2[1]) > 10:\n",
    "            return rect1[1] - rect2[1]\n",
    "        else:\n",
    "            return rect1[0] - rect2[0]\n",
    "    \n",
    "    bounding_boxes = sorted(bounding_boxes, key=functools.cmp_to_key(compare))\n",
    "\n",
    "    display(Image(data=cv2.imencode('.jpg', mask)[1].tobytes()))\n",
    "    return mask, bounding_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7630a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_character(image, model):\n",
    "    # Resize and preprocess the image\n",
    "    image = cv2.resize(image, (50, 50))\n",
    "    image = image.reshape(-1, image.shape[0], 50, 1)\n",
    "\n",
    "    # Predict using the CNN model\n",
    "    classes = model.predict(image)\n",
    "    classes = np.argmax(classes)  # Get the index of the maximum prediction\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50fc106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_number_plate(frame, scale_factor=3):\n",
    "    # Perform object detection using YOLO\n",
    "    detections = model(frame)\n",
    "\n",
    "    # Extract bounding boxes and crop number plate regions\n",
    "    number_plate_box = None\n",
    "    for detection in detections[0].boxes.data:\n",
    "        if detection[5] == 0:  \n",
    "            number_plate_box = detection[:4]\n",
    "            break  \n",
    "            \n",
    "    # Draw bounding box on the original frame\n",
    "    if number_plate_box is not None:\n",
    "        x1, y1, x2, y2 = number_plate_box\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "    \n",
    "    # Crop and preprocess the number plate region\n",
    "    if number_plate_box is not None:\n",
    "        cropped_image = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "        scaled_image = cv2.resize(cropped_image, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)\n",
    "        preprocessed_image = preprocess_image(scaled_image)\n",
    "        thresholded_image = threshold(preprocessed_image)\n",
    "        segmented_characters = segment_characters(thresholded_image)\n",
    "        \n",
    "    return frame, segmented_characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a79253ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLO model\n",
    "model = YOLO('best.pt') \n",
    "model.conf = 0.4  # Confidence threshold for detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49cb0b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Load the character recognition model\n",
    "model_1 = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2603a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the video capture\n",
    "cap = cv2.VideoCapture('video.mp4')  # Replace 'video.mp4' with your video file\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Recognize number plates in the frame\n",
    "    processed_frame, segmented_characters = recognize_number_plate(frame)\n",
    "    \n",
    "    # Iterate over segmented characters and recognize them\n",
    "    plate = ''\n",
    "    for character in segmented_characters:\n",
    "        cnn_prediction = predict_character(character, model_1)\n",
    "\n",
    "        if cnn_prediction < 10:\n",
    "            plate += str(cnn_prediction)\n",
    "        elif cnn_prediction == 10:\n",
    "            plate += 'BA '\n",
    "        elif cnn_prediction == 11:\n",
    "            plate += 'CHA '\n",
    "        elif cnn_prediction == 12:\n",
    "            plate += 'PA '\n",
    "        else:\n",
    "            plate += 'Unknown'\n",
    "    \n",
    "    # Print the recognized number plate\n",
    "    print('Plate:', plate)\n",
    "    \n",
    "# Release the video capture\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
